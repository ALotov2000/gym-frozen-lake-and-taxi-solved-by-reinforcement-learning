{"cells":[{"cell_type":"markdown","metadata":{"id":"d0W-WuYsjWPP"},"source":["# Artificial Intelligence Course - Fall 1402\n","## Computer Assignment #2 - Reinforcement Learning"]},{"cell_type":"markdown","metadata":{"id":"ksnYjMyNPAcn"},"source":["# Table of Contents\n","\n","- [Part 1: Value Iteration & Policy Iteration Algorithms](#1)\n","    - [َQuestion 1:](#1-1)\n","    - [َQuestion 2:](#1-2)\n","    - [َQuestion 3:](#1-3)\n","    - [َQuestion 4:](#1-4)\n","    - [Question 5:](#1-5)\n","        - [Value Iteration](#1-5-1)\n","        - [Policy Iteration](#1-5-2)\n","    - [Question 6:](#1-6)\n","- [Part 2: Q-Learning Algorithm](#2)\n","    - [َQuestion 8:](#2-1)\n","    - [َQuestion 9:](#2-2)\n","    - [َQuestion 10:](#2-3)"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"dpTWKluXMHP5"},"outputs":[],"source":["# import\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import gymnasium as gym\n","from time import sleep, time\n","from typing import *"]},{"cell_type":"code","execution_count":2,"metadata":{"tags":["parameters"]},"outputs":[],"source":["EPSILON = 0.1\n","LEARNING_RATE = 0.1\n","DISCOUNT = 0.9\n","\n","# Q-learning parameters\n","REPS = 20\n","EPISODES = 2000\n","TIME_LIMIT = 200\n","\n","DO_RENDER = False\n","RENDER_FPS = 20\n","\n","STUDENT_NUM = 573"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def monitor_time(f: Callable):\n","    start = time()\n","    result = f()\n","    end = time()\n","    return result, end - start"]},{"cell_type":"markdown","metadata":{"id":"EifP8FUKLXE7"},"source":["## Part 1: Value Iteration & Policy Iteration Algorithms <a name='1'></a>"]},{"cell_type":"markdown","metadata":{},"source":["### Question 1: How does value iteration algorithm find the optimal policy on Markov decision processes(MDPs)? <a name='1-1'></a>"]},{"cell_type":"markdown","metadata":{"id":"iVJmGmCUnIGR"},"source":["Basically to solve an MDP, it is necessary to find an optimal policy for each state. One way to find it is to solve an $n$-equations-and-$n$-unknowns over utility values of each state where $n$ is the number of states. The equations' form is as follows:\n","$$ U(s) = \n","    \\max_{a \\in Actions}\n","        \\sum_{s' \\in States}\n","            Pr(s'|s,a) \\bigg(R(s, a, s') + \\gamma U(s')\\bigg)\n","$$\n","for all $s \\in States$ where $U(s)$ is the utility measure of state $s$, $Pr(s'|s, a)$ is the probability of ending up in $s'$ after taking action $a$ in state $s$, and $R(s, a, s')$ is the reward of taking action $a$ from state $s$ and ending up in $s'$.\n","\n","Now, Imagine $U_i$ where:\n","$$ U_{i+1}(s) \\leftarrow\n","    \\max_{a \\in Actions}\n","        \\sum_{s' \\in States}\n","            Pr(s'|s,a) \\bigg(R(s, a, s') + \\gamma U_i(s')\\bigg) \n","$$\n","and\n","$$ U_0(s) = 0 $$\n","with aforementioned definitions for $Pr$ and $R$. It is provable that $U_i(s)$ will converge on a value for each $s \\in States$. \n","\n","As a result of this convergence, value iteration algorithm thrives. It calculates $U_{i+1}(s)$ for as many times as needed to at last, have the following inequality:\n","$$\\max_{s \\in States} |U_{i+1}(s) - U_i(s)| < \\theta$$\n","where $\\theta$ is the *error* measure.\n","\n","Once $U(s)$ values for all $s \\in States$ are collected, the optimal policy $\\pi(s)$ will be calculated as described below:\n","$$ \\pi(s) = \n","    \\argmax_{a \\in Actions}\n","        \\sum_{s' \\in States}\n","            Pr(s'|s,a) \\bigg(R(s, a, s') + \\gamma U_i(s')\\bigg)\n",".$$\n","\n","P.S. for the sake of simplifying and breaking the equations down to understandable pieces, $Q(s, a)$ is frequently used which is defined as follows:\n","$$ Q(s, a) =\n","    \\sum_{s' \\in States}\n","        Pr(s'|s,a) \\bigg(R(s, a, s') + \\gamma U(s')\\bigg) \n",".$$"]},{"cell_type":"markdown","metadata":{"id":"MO24LtBGLXZ7"},"source":["### Question 2: Complete the given `ValueIterationAgent` class. <a name='1-2'></a>"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"VKP8LjK5jGoW","tags":["value iteration agent"]},"outputs":[],"source":["class ValueIterationAgent:\n","    def __init__(self: Self, env: gym.Env, discount_factor: float, theta:float=1e-8):\n","        self.env = env\n","        self.discount_factor = discount_factor\n","        self.theta = theta\n","        self.state_values = np.zeros(env.observation_space.n)\n","        self.q_values = np.zeros((env.observation_space.n, \n","                    env.action_space.n))\n","        \n","        self.is_value_estimated = False\n","\n","    def value_estimation(self: Self):\n","        if self.is_value_estimated:\n","            return\n","        env, state_values, q_values, discount_factor, theta = \\\n","                self.env, \\\n","                self.state_values, \\\n","                self.q_values, \\\n","                self.discount_factor, \\\n","                self.theta\n","            \n","        delta = np.inf\n","\n","        while(delta > theta):\n","            delta = 0\n","\n","            for state in range(env.observation_space.n):\n","                previous_state_value = state_values[state]\n","\n","                for action in range(env.action_space.n):\n","                    action_value = 0\n","                    for probability, next_state, reward, _ in env.unwrapped.P[state][action]:\n","                        action_value += probability * \\\n","                                (reward + \\\n","                                discount_factor * state_values[next_state])\n","                    q_values[state, action] = action_value\n","\n","                state_values[state] = np.max(q_values[state,:])\n","\n","                delta = np.max([delta, abs(previous_state_value - state_values[state])])\n","                \n","        self.is_value_estimated = True\n","\n","    def take_action(self: Self, action: Any):\n","        next_state, reward, terminated, truncated, _ = self.env.step(action)\n","        return next_state, reward, terminated, truncated\n","\n","    def get_optimal_policy(self: Self, state: Any):\n","        return np.argmax(self.q_values[state,:])\n","\n","    def get_state_values(self: Self):\n","        return self.state_values\n","\n","    def get_q_values(self: Self):\n","        return self.q_values\n","\n","    def reset(self: Self, *args, **kwargs):\n","        initial_state, _ = self.env.reset(*args, **kwargs)\n","        return initial_state, False, False\n","            \n","    def __repr__(self: Self):\n","        env = self.env\n","        nrow, ncol = env.unwrapped.nrow, env.unwrapped.ncol\n","        n = env.observation_space.n\n","        \n","        self.value_estimation()\n","        to_format = np.vectorize(lambda x: f\"{x:.3f}\")\n","        state_values = to_format(self.get_state_values()).reshape(nrow, ncol)\n","        optimal_policy = np.array([self.get_optimal_policy(state) for state in range(n)]).reshape(nrow, ncol)\n","        st = \"\\n\".join([\"-\" * 10,\n","                \"State Utilities:\",\n","                str(state_values),\n","                \"Optimal Policy:\",\n","                str(optimal_policy),\n","                \"-\" * 10])\n","        return st\n","        \n","    __str__ = __repr__"]},{"cell_type":"markdown","metadata":{"id":"frjc5mR4ncm1"},"source":["### Question 3: How does policy iteration algorithm find the optimal policy on MDPs? <a name='1-3'></a>"]},{"cell_type":"markdown","metadata":{},"source":["In order to find the optimal policy for each state, there is another way rather than solving foretold equations. In policy iteration algorithm we start with a random policy function \n","$$ \\pi_0: States \\rightarrow Actions,$$ \n","and \n","$$ U^{\\pi_0}(s) = 0.$$\n","In each step thereafter, with the purpose of improving our policy, policy iteration algorithms carry out two procedures:\n","- **policy evaluation**, which evaluates $U^{\\pi_i}$ for each policy,\n","- **policy improvement**, which improves $\\pi_i$ and gives $\\pi_{i+1}: States \\rightarrow Actions$.\n","\n","For policy improvement, it uses the following method:\n","$$ \\pi_{i+1}(s) \\leftarrow \\argmax_{a \\in Actions}\n","    \\sum_{s' \\in States}\n","        Pr(s'|s, a) \\bigg(R(s, a, s') + \\gamma U^{\\pi_i}(s)\\bigg)\n",".$$\n","\n","For policy evaluation, similarly to value iteration, we must solve an $n$-equations-and-$n$-unknowns problem that is as follows:\n","$$ U^{\\pi_i}(s) = \\sum_{s' \\in States}\n","    Pr(s'|s, \\pi_i(s)) \\bigg(R(s, \\pi_i(s), s') + \\gamma U^{\\pi_i}(s)\\bigg)\n",".$$\n","However, unlike previous equations, this time because there is no non-linear function such as $max$, the equation system is linear and, therefore, soluable by *gaussian elimination method* with $O(n^3)$ time complexity. Even though gaussian elimination method is quite practical in small environments, it takes too long to be carried out on a big one. Thankfully, there is another way.\n","If we define $U_j^{\\pi_i}$ so that:\n","$$ U_{j+1}^{\\pi_i}(s) \\leftarrow \\sum_{s' \\in States}\n","    Pr(s'|s, \\pi_i(s)) \\bigg(R(s, \\pi_i(s), s') + \\gamma U_j^{\\pi_i}(s)\\bigg)\n",",$$\n","where $\\forall s \\in States\\bigg(U_0^{\\pi_i}(s) = 0\\bigg)$, it is provable that $U_j^{\\pi_i}$ converges on the answer of the equations. This procedure is called *simplified value iteration* and if a policy iteration algorithm uses it, it will be called a *modified policy iteration algorithm*.\n","In this assignment, the second approach is used."]},{"cell_type":"markdown","metadata":{"id":"V4DcH5yJLXqH"},"source":["### Question 4: Complete the given `ModifiedPolicyIterationAgent` class. <a name='1-4'></a>"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1698433256083,"user":{"displayName":"Mohammad Saadati","userId":"00242434153251678664"},"user_tz":-210},"id":"XjSb1lX147hd","tags":["modified policy iteration agent"]},"outputs":[],"source":["class ModifiedPolicyIterationAgent():\n","    def __init__(self: Self, env: gym.Env, discount_factor:float, theta:float=1e-8):\n","        self.env = env\n","        self.discount_factor = discount_factor\n","        self.theta = theta\n","        self.state_values = np.zeros((env.observation_space.n))\n","        self.q_values = np.zeros((env.observation_space.n, env.action_space.n))\n","        self.policy = np.random.randint(env.action_space.n, size=env.observation_space.n)\n","        self.policy_stable = False\n","\n","    def policy_evaluation(self):\n","        env, discount_factor, theta, state_values, policy = self.env, \\\n","                self.discount_factor, \\\n","                self.theta, \\\n","                self.state_values, \\\n","                self.policy\n","        delta = np.inf\n","\n","        while(delta > theta):\n","\n","            delta = 0\n","\n","            for state in range(env.observation_space.n):\n","\n","                previous_state_value = state_values[state]\n","\n","                new_state_value = 0\n","                for probability, next_state, reward, _ in env.unwrapped.P[state][policy[state]]:\n","                    new_state_value += probability * \\\n","                                (reward + \\\n","                                discount_factor * state_values[next_state])\n","                state_values[state] = new_state_value\n","\n","                delta = np.max([delta, abs(previous_state_value - new_state_value)])\n","\n","    def policy_improvement(self: Self):\n","        env, discount_factor, state_values, q_values, policy = self.env, \\\n","                self.discount_factor, \\\n","                self.state_values, \\\n","                self.q_values, \\\n","                self.policy\n","        \n","        is_policy_stable = True\n","        for state in range(env.observation_space.n):\n","            old_policy = policy[state]\n","\n","            for action in range(env.action_space.n):\n","\n","                action_value = 0\n","                for probability, next_state, reward, _ in env.unwrapped.P[state][action]:\n","                    action_value += probability * \\\n","                                (reward + \\\n","                                discount_factor * state_values[next_state])\n","                q_values[state, action] = action_value\n","\n","            policy[state] = np.argmax(q_values[state,:])\n","\n","            if old_policy != policy[state]:\n","                is_policy_stable = False\n","        \n","        self.policy_stable = is_policy_stable\n","\n","    def policy_estimation(self: Self):\n","        \n","        while not self.policy_stable:\n","            self.policy_evaluation()\n","            self.policy_improvement()\n","\n","    def take_action(self: Self, action: Any):\n","        next_state, reward, terminated, truncated, _ = self.env.step(action)\n","        return next_state, reward, terminated, truncated\n","\n","    def get_optimal_policy(self: Self, state):\n","        return self.policy[state]\n","\n","    def get_state_values(self: Self):\n","        return self.state_values\n","\n","    def get_q_values(self: Self):\n","        return self.q_values\n","\n","    def reset(self: Self, *args, **kwargs):\n","        initial_state, _ = self.env.reset(*args, **kwargs)\n","        return initial_state, False, False\n","            \n","    def __repr__(self: Self):\n","        env, policy = self.env, self.policy\n","        nrow, ncol = env.unwrapped.nrow, env.unwrapped.ncol\n","        n = env.observation_space.n\n","        \n","        self.policy_estimation()\n","        to_format = np.vectorize(lambda x: f\"{x:.3f}\")\n","        state_values = to_format(self.get_state_values()).reshape(nrow, ncol)\n","        optimal_policy = np.array(policy).reshape(nrow, ncol)\n","        st = \"\\n\".join([\"-\" * 10,\n","                \"State Utilities:\",\n","                str(state_values),\n","                \"Optimal Policy:\",\n","                str(optimal_policy),\n","                \"-\" * 10])\n","        return st\n","        \n","    __str__ = __repr__"]},{"cell_type":"markdown","metadata":{"id":"u4G-kVjmLYj4"},"source":["### Question 5: Run both algorithms on the Frozen Lake environment. <a name='1-5'></a>"]},{"cell_type":"markdown","metadata":{"id":"PB651-ZY4vjE"},"source":["#### Value Iteration: <a name='1-5-1'></a>"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"RGYLOfYAuKjY"},"outputs":[{"data":{"text/plain":["----------\n","State Utilities:\n","[['0.069' '0.061' '0.074' '0.056']\n"," ['0.092' '0.000' '0.112' '0.000']\n"," ['0.145' '0.247' '0.300' '0.000']\n"," ['0.000' '0.380' '0.639' '0.000']]\n","Optimal Policy:\n","[[0 3 0 3]\n"," [0 0 0 0]\n"," [3 1 0 0]\n"," [0 2 1 0]]\n","----------"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["env = gym.make('FrozenLake-v1', \n","        desc=None, \n","        map_name=\"4x4\", \n","        is_slippery=True,)\n","\n","agent = ValueIterationAgent(env, DISCOUNT)\n","agent.value_estimation()\n","agent\n"]},{"cell_type":"markdown","metadata":{"id":"ipZlzoXH40Mn"},"source":["#### Policy Iteration: <a name='1-5-2'></a>"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"7Vxf_xKc44QT"},"outputs":[{"data":{"text/plain":["----------\n","State Utilities:\n","[['0.069' '0.061' '0.074' '0.056']\n"," ['0.092' '0.000' '0.112' '0.000']\n"," ['0.145' '0.247' '0.300' '0.000']\n"," ['0.000' '0.380' '0.639' '0.000']]\n","Optimal Policy:\n","[[0 3 0 3]\n"," [0 0 0 0]\n"," [3 1 0 0]\n"," [0 2 1 0]]\n","----------"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["env = gym.make('FrozenLake-v1', \n","        desc=None, \n","        map_name=\"4x4\", \n","        is_slippery=True)\n","\n","agent = ModifiedPolicyIterationAgent(env, DISCOUNT)\n","agent.policy_estimation()\n","agent"]},{"cell_type":"markdown","metadata":{},"source":["### Question 6: Compare the returned state values and policies of Value Iteration and Policy Iteration. Next, answer which one has been quicker.<a name='1-6'></a>"]},{"cell_type":"markdown","metadata":{},"source":["As shown in the previous section, state utility values alongside optimal policies for both algorithms have converged on a single value — which is intuitively obvious since if they had converged to two different values, it would have been contradictory to the very definition of convergence itself.\n","\n","Also, to be able to measure the time taken by each agent to provide the optimal policy, each will be run $N$ times, every time assessed by the `monitor_time` function. This function is designed to return any function's running duration. Next, these assessments will be averaged and printed:"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["(0.037516562938690184, 0.04498790740966797)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["N = 100\n","average_value_estimation_time = 0\n","average_policy_estimation_time = 0\n","for i in range(N):\n","    env = gym.make('FrozenLake-v1', \n","            desc=None, \n","            map_name=\"4x4\", \n","            is_slippery=True)\n","\n","    value_iterative_agent = ValueIterationAgent(env, DISCOUNT)\n","    policy_iterative_agent = ModifiedPolicyIterationAgent(env, DISCOUNT)\n","    \n","    _, value_estimation_time = monitor_time(lambda: value_iterative_agent.value_estimation())\n","    _, policy_estimation_time = monitor_time(lambda: policy_iterative_agent.policy_estimation())\n","    \n","    average_value_estimation_time += value_estimation_time\n","    average_policy_estimation_time += policy_estimation_time\n","    \n","average_value_estimation_time /= N\n","average_policy_estimation_time /= N\n","\n","average_value_estimation_time, average_policy_estimation_time"]},{"cell_type":"markdown","metadata":{},"source":["As you can see, in this special case Value Iteration algorithm wins the race by quite a small margin."]},{"cell_type":"markdown","metadata":{},"source":["To close the first part in style, a graphical representation of an agent taking the optimal policy to the goal is provided."]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["if DO_RENDER:\n","    env = gym.make('FrozenLake-v1', \n","            desc=None, \n","            map_name=\"4x4\", \n","            is_slippery=True,\n","            render_mode='human' if DO_RENDER else None)\n","    env.metadata['render_fps'] = RENDER_FPS\n","\n","    agent = ValueIterationAgent(env, DISCOUNT)\n","    agent.value_estimation()\n","    state, terminated, truncated = agent.reset(seed=STUDENT_NUM)\n","    try:\n","        while not (terminated or truncated):\n","            action = agent.get_optimal_policy(state)\n","            state, _, terminated, truncated = agent.take_action(action) \n","            env.render()\n","    finally:\n","        env.close()"]},{"cell_type":"markdown","metadata":{"id":"hLtPLm-ELpG9"},"source":["## Part 2: Q-Learning Algorithm <a name='2'></a>"]},{"cell_type":"markdown","metadata":{},"source":["### Question 7: How does Temporal-Difference Q-Learning algorithm work? <a name='2-7'></a>"]},{"cell_type":"markdown","metadata":{},"source":["Q-Learning algorithm learns Q-value of each $(state, action)$ by applying the following assignment every time action $a$ is perceived that transitions $s$ to $s'$: ($Q(s, a)$ is initially zero for all $(state, action)$)\n","$$ Q(s, a) \\leftarrow (1 - \\alpha)Q(s, a) + \\alpha(R(s, a, s') + \\gamma \\max_{a'} Q(s', a') - Q(s, a)) $$\n","where $\\alpha$ and $\\gamma$ are the learning rate and the discounting factor respectively. The naming comes from teaching the agent by adding the temporal difference, $[R(s, a, s') + \\gamma \\max_{a'} Q(s', a') - Q(s, a)]$, to the Q-table.  \n","After $Q(s, a)$ is updated, Q-value for all $s''\\in States$ and $a''\\in Actions$ should be re-estimated to be compatible with the new percept.  \n","Next, optimal policy $\\pi^*$ for each $s\\in States$ is evaluated the following way:\n","$$ \\pi^*(s) = \\max_{a\\in Actions} Q(s, a) $$\n","which if taken will maximize $Q(s, a)$ for all the percepts received."]},{"cell_type":"markdown","metadata":{"id":"oZJAP4nMLpiZ"},"source":["### Question 8: Complete the given `QLearningAgent` class. <a name='2-8'></a>"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":503,"status":"ok","timestamp":1698434549406,"user":{"displayName":"Mohammad Saadati","userId":"00242434153251678664"},"user_tz":-210},"id":"Ue4m5fg9450B"},"outputs":[],"source":["class QLearningAgent:\n","    def __init__(self: Self, \n","                env: gym.Env, \n","                epsilon: float, \n","                learning_rate: float, \n","                discount_factor: float, \n","                seed: int):\n","        self.env = env\n","        self.epsilon = epsilon\n","        self.learning_rate = learning_rate\n","        self.olr = learning_rate\n","        self.discount_factor = discount_factor\n","        self.q_table = np.zeros((env.observation_space.n, env.action_space.n))\n","        self.seed = seed\n","        self.rng = np.random.default_rng()\n","\n","    def choose_action(self: Self, state: int):\n","        env, epsilon, q_table, rng = self.env, self.epsilon, self.q_table, self.rng\n","        \n","        decision = rng.random() <= epsilon\n","        action = rng.integers(env.action_space.n) if decision else np.argmax(q_table[state])\n","        \n","        return action\n","\n","    def update_q_table(self: Self, state: int, action: int, next_state: int, reward: float):\n","        a, q_table, discount = self.learning_rate, self.q_table, self.discount_factor\n","        q_table[state, action] = (1 - a) * q_table[state, action] \\\n","                + a * (\\\n","                        (reward + discount * np.max(q_table[next_state])) \\\n","                        - q_table[state, action])\n","\n","    def decay_epsilon(self: Self, episode: int):\n","        self.epsilon *= 1 - episode / EPISODES\n","\n","    def decrease_learning_rate(self: Self, episode: int):\n","        pass\n","\n","    def take_action(self: Self, action: int):\n","        next_state, reward, terminated, truncated, _ = self.env.step(action)\n","        return next_state, reward, terminated, truncated\n","\n","    def get_optimal_policy(self: Self, state: int):\n","        return np.argmax(self.q_table[state])\n","\n","    def get_q_values(self: Self):\n","        return self.q_table\n","\n","    def reset(self: Self):\n","        initial_state, _ = self.env.reset(seed=self.seed, )\n","        return initial_state, False, False\n","            \n","    def __repr__(self: Self):\n","        env = self.env\n","        nrow, ncol, npass, nact = 5, 5, 5, 4\n","        n = env.observation_space.n\n","        q_values = self.get_q_values()\n","        \n","        to_format = np.vectorize(lambda x: f\"{x:.3f}\")\n","        state_values = to_format(np.max(q_values, axis=1)).reshape(nrow, ncol, npass, nact)\n","        optimal_policy = np.argmax(q_values, axis=1).reshape(nrow, ncol, npass, nact)\n","        st = \"\\n\".join([\"-\" * 10,\n","                \"State Utilities:\",\n","                str(state_values),\n","                \"Optimal Policy:\",\n","                str(optimal_policy),\n","                \"-\" * 10])\n","        return st\n","        \n","    __str__ = __repr__"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"Et2PlHqMMOoM"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["env = gym.wrappers.TimeLimit(gym.make('Taxi-v3'), TIME_LIMIT)\n","reward_sum = np.zeros((REPS, EPISODES))\n","for rep in range(REPS):\n","    agent = QLearningAgent(env, EPSILON, LEARNING_RATE, DISCOUNT, STUDENT_NUM)\n","    for episode in range(EPISODES):\n","        state, terminated, truncated = agent.reset()\n","        \n","        while not (terminated or truncated):\n","            action = agent.choose_action(state)\n","            next_state, reward, terminated, truncated = agent.take_action(action)\n","            reward_sum[rep, episode] += reward\n","            \n","            agent.update_q_table(state, action, next_state, reward)\n","            agent.decay_epsilon(episode)\n","            agent.decrease_learning_rate(episode)\n","            \n","            state = next_state\n","fig, ax = plt.subplots()\n","ax.plot(np.arange(EPISODES), np.average(reward_sum, axis=0))\n","ax.grid(True, axis='y')\n","ax.set_xlabel('episode')\n","ax.set_ylabel('average reward')\n","ax.set_title('Convergence of Temporal-Difference Q-Learning Algorithm for gym.Taxi-v3')\n","plt.show()\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["if DO_RENDER:\n","    env = gym.make('Taxi-v3', render_mode='human')\n","    env.metadata['render_fps'] = RENDER_FPS\n","    \n","    state, _ = env.reset(seed=STUDENT_NUM)\n","    terminated, truncated = False, False\n","    try:\n","        while not (terminated or truncated):\n","            action = agent.choose_action(state)\n","            state, _, terminated, truncated, _ = env.step(action)\n","    finally:\n","        env.close()"]},{"cell_type":"markdown","metadata":{"id":"c5HFAMk-Lpvs"},"source":["<a name='2-2'></a>\n","### Question 9:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qgRhXXmwo6MT"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"BVcMKEGDQWdU"},"source":["<a name='2-3'></a>\n","### Question 10:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FlHPV0kqQWdU"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":0}
